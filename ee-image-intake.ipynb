{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Bounding Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get coordinates, build dataframe, crop images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/handcropped\n",
    "\n",
    "rows = [[]]\n",
    "index = 0\n",
    "#bounding boxes were drawn in blue-green using MS Paint\n",
    "myColor = [0,255,255]\n",
    "myColor = np.array(myColor, dtype = 'uint8')\n",
    "\n",
    "path = 'path_to_data'\n",
    "folder = os.listdir(path)\n",
    "for img in folder:\n",
    "    image = os.path.join(path, img)\n",
    "    image = cv2.imread(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #eliminate all pixels that are not blue-green\n",
    "    mask = cv2.inRange(image, myColor, myColor)\n",
    "    output = cv2.bitwise_and(image, image, mask = mask)\n",
    "    gray = cv2.cvtColor(output, cv2.COLOR_RGB2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 50, 255, 0)\n",
    "    \n",
    "    #get contours (corner coordinates) of bounding box\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    x = 0\n",
    "    y = 0\n",
    "    \n",
    "    #get each corner\n",
    "    for botright in contours:\n",
    "        if botright[0][0][0] >= x:\n",
    "            x2 = x = botright[0][0][0]\n",
    "        if botright[0][0][1] >= y:\n",
    "            y2 = y = botright[0][0][1]\n",
    "    botright = [x,y]\n",
    "    x = 100000\n",
    "    y = 0\n",
    "    for botleft in contours:\n",
    "        if botleft[0][0][0] <= x:\n",
    "            x = botleft[0][0][0]\n",
    "        if botleft[0][0][1] >= y:\n",
    "            y = botleft[0][0][1]\n",
    "    botleft = [x,y]\n",
    "    x = 100000\n",
    "    y = 100000\n",
    "    for topleft in contours:\n",
    "        if topleft[0][0][0] <= x:\n",
    "            x1 = x = topleft[0][0][0]\n",
    "        if topleft[0][0][1] <= y:\n",
    "            y1 = y = topleft[0][0][1]\n",
    "    topleft = [x,y]\n",
    "    x = 0\n",
    "    y = 100000\n",
    "    for topright in contours:\n",
    "        if topright[0][0][0] >= x:\n",
    "            x = topright[0][0][0]\n",
    "        if topright[0][0][1] <= y:\n",
    "            y = topright[0][0][1]\n",
    "    topright = [x,y]\n",
    "    #diagnostic check\n",
    "    print('TL: {}, TR: {}, BL: {}, BR: {}'.format(topleft, topright, botleft, botright))\n",
    "    \n",
    "    #image naming conventions bad, ignore\n",
    "    img = img.replace(' - BOUNDED', '')\n",
    "    imgname = img\n",
    "    \n",
    "    #diagnostic check\n",
    "    print(imgname, x1, y1, x2, y2)\n",
    "    \n",
    "    #add to dataframe\n",
    "    rows.append([imgname, x1, y1, x2, y2])\n",
    "    \n",
    "    #crop image to bounding box and save\n",
    "    cropped_image = image[topleft[1]+10:botleft[1]-10, topleft[0]+10:topright[0]-10]\n",
    "    imgname = os.path.join('/kaggle/working/handcropped', img)\n",
    "    try:\n",
    "        cv2.imwrite(imgname, cropped_image)\n",
    "    except Exception:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CSV to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['ImageName', 'x1', 'y1', 'x2', 'y2']\n",
    "\n",
    "filename = 'boundingboxes.csv'\n",
    "\n",
    "\n",
    "with open(filename, 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(fields)\n",
    "    csvwriter.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "# Create a new workbook and select the active sheet\n",
    "workbook = openpyxl.Workbook()\n",
    "worksheet = workbook.active\n",
    "\n",
    "# Define the fields and write the header row\n",
    "fields = ['ImageName', 'x1', 'y1', 'x2', 'y2']\n",
    "worksheet.append(fields)\n",
    "\n",
    "\n",
    "for row in rows:\n",
    "    worksheet.append(row)\n",
    "\n",
    "# Save the workbook as an Excel file\n",
    "filename = 'boundingboxes.xlsx'\n",
    "workbook.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress cropped images for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip /kaggle/working/handcropped/handcropped.zip -r /kaggle/working/handcropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Sample of Cropped Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "croppedfolder = os.listdir('/kaggle/working/handcropped')\n",
    "rows = 2\n",
    "columns = 2\n",
    "index = 1\n",
    "\n",
    "for i, img in sample(list(enumerate(sorted(croppedfolder))), 4):\n",
    "    img = os.path.join('/kaggle/working/handcropped', img)\n",
    "    image = cv2.imread(img)\n",
    "    fig.add_subplot(rows, columns, index)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('{} - {} down'.format(img, i))\n",
    "    print(img)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from openpyxl import load_workbook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import mimetypes\n",
    "import argparse\n",
    "#import imutils\n",
    "import random\n",
    "from random import sample\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "\n",
    "random.seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hflip_with_default_label(image, bboxes):\n",
    "    if not bboxes:\n",
    "        return image, []\n",
    "\n",
    "    labels = ['box'] * len(bboxes)\n",
    "    transform = A.Compose([\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "    transformed = transform(image=image, bboxes=bboxes, labels=labels)\n",
    "    return transformed['image'], transformed['bboxes']\n",
    "\n",
    "\n",
    "def vflip_with_default_label(image, bboxes):\n",
    "    if not bboxes:\n",
    "        return image, []\n",
    "\n",
    "    labels = ['box'] * len(bboxes)\n",
    "    transform = A.Compose([\n",
    "        A.VerticalFlip(p=1.0),\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "    transformed = transform(image=image, bboxes=bboxes, labels=labels)\n",
    "    return transformed['image'], transformed['bboxes']\n",
    "\n",
    "def blur_with_default_label(image, bboxes):\n",
    "    if not bboxes:\n",
    "        return image, []\n",
    "\n",
    "    labels = ['box'] * len(bboxes)\n",
    "    transform = A.Compose([\n",
    "        A.GaussianBlur (blur_limit=(7, 7), sigma_limit=0, always_apply=True, p=1.0)\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "    transformed = transform(image=image, bboxes=bboxes, labels=labels)\n",
    "    return transformed['image'], transformed['bboxes']\n",
    "\n",
    "\n",
    "def opticaldistort_with_default_label(image, bboxes):\n",
    "    if not bboxes:\n",
    "        return image, []\n",
    "\n",
    "    labels = ['box'] * len(bboxes)\n",
    "    transform = A.Compose([\n",
    "        A.OpticalDistortion (distort_limit=0.35, shift_limit=0.35, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=True, p=1.0)\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "    transformed = transform(image=image, bboxes=bboxes, labels=labels)\n",
    "    return transformed['image'], transformed['bboxes']\n",
    "\n",
    "def rot90_with_default_label(image, bboxes):\n",
    "    if not bboxes:\n",
    "        return image, []\n",
    "\n",
    "    labels = ['box'] * len(bboxes)\n",
    "    transform = A.Compose([\n",
    "        A.RandomRotate90(p=1.0),\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "    transformed = transform(image=image, bboxes=bboxes, labels=labels)\n",
    "    return transformed['image'], transformed['bboxes']\n",
    "\n",
    "def randomscale_with_default_label(image, bboxes):\n",
    "    if not bboxes:\n",
    "        return image, []\n",
    "\n",
    "    labels = ['box'] * len(bboxes)\n",
    "    transform = A.Compose([\n",
    "        A.RandomScale(scale_limit=0.35, interpolation=1, always_apply=True, p=1.0),\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "    transformed = transform(image=image, bboxes=bboxes, labels=labels)\n",
    "    return transformed['image'], transformed['bboxes']\n",
    "\n",
    "def mix_with_default_label(image, bboxes):\n",
    "    if not bboxes:\n",
    "        return image, []\n",
    "\n",
    "    labels = ['box'] * len(bboxes)\n",
    "    transform = A.Compose([\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.GaussianBlur (blur_limit=(7, 7), sigma_limit=0, always_apply=True, p=1.0),\n",
    "        A.OpticalDistortion (distort_limit=0.35, shift_limit=0.35, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=True, p=1.0),\n",
    "        A.RandomRotate90(p=1.0),\n",
    "        A.RandomScale(scale_limit=0.35, interpolation=1, always_apply=True, p=1.0),\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "    transformed = transform(image=image, bboxes=bboxes, labels=labels)\n",
    "    return transformed['image'], transformed['bboxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"data_path\"\n",
    "img_path = \"img_path\"\n",
    "df = load_workbook(df_path)\n",
    "df = df.active\n",
    "rows = [[]]\n",
    "data = []\n",
    "targets = []\n",
    "filenames = []\n",
    "labels = []\n",
    "idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(2,df.max_row):\n",
    "    rows.append([df['A'+str(f)].value,df['B'+str(f)].value, df['C'+str(f)].value,df['D'+str(f)].value, df['E'+str(f)].value])\n",
    "rows = rows[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/verticalflippedimages\n",
    "!mkdir /kaggle/working/horizontalflippedimages\n",
    "!mkdir /kaggle/working/blurredimages\n",
    "!mkdir /kaggle/working/distortedimages\n",
    "!mkdir /kaggle/working/rotatedimages\n",
    "!mkdir /kaggle/working/scaledimages\n",
    "!mkdir /kaggle/working/mixedimages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "fields = ['ImageName', 'Topleft', 'TopRight', 'BottomLeft', 'BottomRight']\n",
    "\n",
    "csvname = 'newtag_boundaries.csv'\n",
    "with open(csvname, 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(fields)\n",
    "    for i, f in enumerate(rows):\n",
    "        print('{}/{}'.format(i+1, len(rows)))\n",
    "        print(f)\n",
    "        filename = f[0]\n",
    "        startx = f[1]\n",
    "        starty = f[2]\n",
    "        endx = f[3]\n",
    "        endy = f[4]\n",
    "        filenames.append(filename)\n",
    "\n",
    "        imgpath = os.path.join(img_path, filename.replace('jpg', 'JPG'))\n",
    "        print(imgpath)\n",
    "        try:\n",
    "            image = cv2.imread(imgpath)\n",
    "            (h, w) = image.shape[:2]\n",
    "            bbox = [startx, starty, endx, endy]\n",
    "            bbox = [[int(coord) for coord in bbox]]\n",
    "            targets.append((startx, starty, endx, endy))\n",
    "\n",
    "            vflipimg, vflipbox = vflip_with_default_label(image=image, bboxes=bbox)\n",
    "            hflipimg, hflipbox = hflip_with_default_label(image = image, bboxes = bbox)\n",
    "            blurimg, blurbox = blur_with_default_label(image = image, bboxes = bbox)\n",
    "            distortimg, distortbox = opticaldistort_with_default_label(image = image, bboxes = bbox)\n",
    "            rotimg, rotbox = rot90_with_default_label(image = image, bboxes = bbox)\n",
    "            scaleimg, scalebox = randomscale_with_default_label(image = image, bboxes = bbox)\n",
    "            miximg, mixbox = mix_with_default_label(image = image, bboxes = bbox)\n",
    "            vflipbox = ['{} - VFLIP.jpg'.format(filename.replace('.jpg', '').replace(' - ORIGINAL', '').replace('.JPG', '')), vflipbox[0][0], vflipbox[0][1], vflipbox[0][2], vflipbox[0][3]]\n",
    "            hflipbox = ['{} - HFLIP.jpg'.format(filename.replace('.jpg', '').replace(' - ORIGINAL', '').replace('.JPG', '')), hflipbox[0][0], hflipbox[0][1], hflipbox[0][2], hflipbox[0][3]]\n",
    "            blurbox = ['{} - BLURRED.jpg'.format(filename.replace('.jpg', '').replace(' - ORIGINAL', '').replace('.JPG', '')), blurbox[0][0], blurbox[0][1], blurbox[0][2], blurbox[0][3]]\n",
    "            distortbox = ['{} - DISTORTED.jpg'.format(filename.replace('.jpg', '').replace(' - ORIGINAL', '').replace('.JPG', '')), distortbox[0][0], distortbox[0][1], distortbox[0][2], distortbox[0][3]]\n",
    "            rotbox = ['{} - ROTATED.jpg'.format(filename.replace('.jpg', '').replace('.JPG', '')), int(rotbox[0][0]), int(rotbox[0][1]), int(rotbox[0][2]), int(rotbox[0][3])]\n",
    "            scalebox = ['{} - SCALED.jpg'.format(filename.replace('.jpg', '').replace('.JPG', '')), int(scalebox[0][0]), int(scalebox[0][1]), int(scalebox[0][2]), int(scalebox[0][3])]\n",
    "            mixbox = ['{} - MIXED.jpg'.format(filename.replace('.jpg', '').replace('.JPG', '')), int(mixbox[0][0]), int(mixbox[0][1]), int(mixbox[0][2]), int(mixbox[0][3])]\n",
    "            bbox = [f[0], bbox[0][0], bbox[0][1], bbox[0][2], bbox[0][3]]\n",
    "            csvwriter.writerow(bbox)\n",
    "            csvwriter.writerow(vflipbox)\n",
    "            csvwriter.writerow(hflipbox)\n",
    "            csvwriter.writerow(blurbox)\n",
    "            csvwriter.writerow(distortbox)\n",
    "            csvwriter.writerow(rotbox)\n",
    "            csvwriter.writerow(scalebox)\n",
    "            csvwriter.writerow(mixbox)\n",
    "            cv2.imwrite(os.path.join('/kaggle/working/verticalflippedimages', f[0].replace('.jpg', '').replace('.JPG', '') + ' - VFLIP.jpg'), vflipimg)\n",
    "            cv2.imwrite(os.path.join('/kaggle/working/horizontalflippedimages', f[0].replace('.jpg', '').replace('.JPG', '') + ' - HFLIP.jpg'), hflipimg)\n",
    "            cv2.imwrite(os.path.join('/kaggle/working/blurredimages', f[0].replace('.jpg', '').replace('.JPG', '') + ' - BLURRED.jpg'), blurimg)\n",
    "            cv2.imwrite(os.path.join('/kaggle/working/distortedimages', f[0].replace('.jpg', '').replace('.JPG', '') + ' - DISTORTED.jpg'), distortimg)\n",
    "            cv2.imwrite(os.path.join('/kaggle/working/rotatedimages', f[0].replace('.jpg', '').replace('.JPG', '') + ' - ROTATED.jpg'), rotimg)\n",
    "            try:\n",
    "                cv2.imwrite(os.path.join('/kaggle/working/scaledimages', f[0].replace('.jpg', '').replace('.JPG', '') + ' - SCALED.jpg'), scaleimg)\n",
    "            except:\n",
    "                print('error in save scaled')\n",
    "            print(' THE LOOP WORKED')\n",
    "            cv2.imwrite(os.path.join('/kaggle/working/mixedimages', f[0].replace('.jpg', '').replace('.JPG', '') + ' - MIXED.jpg'), miximg)\n",
    "        except:\n",
    "            print('File not Found:', imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip /kaggle/working/augmented.zip -r /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "fields = ['ImageName', 'TopLeft', 'TopRight', 'BottomLeft', 'BottomRight']\n",
    "\n",
    "filename = 'newtag_boundaries.csv'\n",
    "\n",
    "with open(filename, 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(fields)\n",
    "    csvwriter.writerows(vflip_boxes)\n",
    "    for row, image, box in zip(rows, vflip_imgs, vflip_boxes):\n",
    "        cv2.imwrite(os.path.join('/kaggle/working/verticalflippedimages', row[0]), image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Tag-Cropping Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from openpyxl import load_workbook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import mimetypes\n",
    "import argparse\n",
    "import random\n",
    "from random import sample\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tag Image Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "source_folder1 = '/kaggle/input/augmented/Images'\n",
    "source_folder2 = '/kaggle/input/augmented-images-2/Images 2'\n",
    "source_folder3 = '/kaggle/input/1016-augmented/Images 3'\n",
    "destination_folder = '/kaggle/working/Images'\n",
    "\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "for i, file_name in enumerate(os.listdir(source_folder1)):\n",
    "    print('Progress: {}/{}'.format(i, len(os.listdir(source_folder1))), end = '\\r')\n",
    "    shutil.copy2(os.path.join(source_folder1, file_name), destination_folder)\n",
    "\n",
    "for o, file_name in enumerate(os.listdir(source_folder2)):\n",
    "    print('Progress: {}/{}'.format(o, len(os.listdir(source_folder2))), end = '\\r')\n",
    "    shutil.copy2(os.path.join(source_folder2, file_name), destination_folder)\n",
    "\n",
    "\n",
    "for u, file_name in enumerate(os.listdir(source_folder3)):\n",
    "    print('Progress: {}/{}'.format(u, len(os.listdir(source_folder3))), end = '\\r')\n",
    "    shutil.copy2(os.path.join(source_folder3, file_name), destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"/kaggle/input/1016-augmented/augmented_boundary_master.xlsx\"\n",
    "img_path = \"/kaggle/working/Images\"\n",
    "df = load_workbook(df_path)\n",
    "df = df.active\n",
    "rows = [[]]\n",
    "data = []\n",
    "targets = []\n",
    "filenames = []\n",
    "trynames = []\n",
    "labels = []\n",
    "idx = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning/Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(2,df.max_row):\n",
    "    tryname = df['A'+str(f)].value\n",
    "    augmented = 0\n",
    "    for effect in ['VFLIP', 'HFLIP', 'DISTORTED', 'MIXED', 'ROTATED', 'SCALED', 'BLURRED']:\n",
    "        if effect in tryname:\n",
    "            augmented = 1\n",
    "            rows.append([df['A'+str(f)].value,df['B'+str(f)].value, df['C'+str(f)].value,df['D'+str(f)].value, df['E'+str(f)].value] )\n",
    "            #if tryname in os.listdir('/kaggle/input/cropped-images/1003 cropped images') or tryname.replace('jpg', 'JPG') in os.listdir('/kaggle/input/1016-augmented/toAugment'):\n",
    "    if augmented != 1:\n",
    "        trynames.append([df['A'+str(f)].value,df['B'+str(f)].value, df['C'+str(f)].value,df['D'+str(f)].value, df['E'+str(f)].value] )\n",
    "rows = rows[1:]\n",
    "print(len(rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(rows)\n",
    "random.shuffle(trynames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgnames = []\n",
    "bboxcoords = []\n",
    "trans_imgs = []\n",
    "trans_imgs = []\n",
    "trans_boxes = []\n",
    "#print(len(rows))\n",
    "for i, f in enumerate(rows):\n",
    "    print('progress: {}/{} *** '.format(i, len(rows)), end = '\\r')\n",
    "    # print(f[0])\n",
    "    filename = f[0]\n",
    "    if filename not in os.listdir('/kaggle/working/Images'):\n",
    "        print('not in here')\n",
    "        continue\n",
    "    if '0164' in filename:\n",
    "        filename = filename.replace('site_1', 'site_2').replace('002','001')\n",
    "        pass\n",
    "    #print(filename)\n",
    "    startx = int(f[1])\n",
    "    starty = int(f[2])\n",
    "    endx = int(f[3])\n",
    "    endy = int(f[4])\n",
    "    imgnames.append(filename)\n",
    "    try:\n",
    "        imgpath = os.path.join(img_path, filename)\n",
    "\n",
    "        image = cv2.imread(imgpath)\n",
    "        #1\n",
    "        (h, w) = image.shape[:2]\n",
    "        bbox = [startx, starty, endx, endy]\n",
    "\n",
    "        bbox = [[int(coord) for coord in bbox]]\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            print('trying with - BOUNDED added')\n",
    "            try:\n",
    "                imgpath = os.path.join(img_path, filename).replace('.jpg', ' - BOUNDED.jpg')\n",
    "\n",
    "                image = cv2.imread(imgpath)\n",
    "                #2\n",
    "                (h, w) = image.shape[:2]\n",
    "                bbox = [startx, starty, endx, endy]\n",
    "\n",
    "                bbox = [[int(coord) for coord in bbox]]\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            except AttributeError:\n",
    "                try:\n",
    "                    print('trying .JPG')\n",
    "                    imgpath = os.path.join(img_path, filename).replace('.jpg', '.JPG')\n",
    "\n",
    "                    image = cv2.imread(imgpath)\n",
    "                    #3\n",
    "                    (h, w) = image.shape[:2]\n",
    "                    bbox = [startx, starty, endx, endy]\n",
    "\n",
    "                    bbox = [[int(coord) for coord in bbox]]\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                except FileNotFoundError or AttributeError:\n",
    "                    continue\n",
    "        except FileNotFoundError or AttributeError:\n",
    "            continue\n",
    "    hflipimg, hflipbox = hflip_with_default_label(image=image, bboxes=bbox)\n",
    "    trans_imgs.append(hflipimg)\n",
    "    trans_boxes.append(hflipbox)\n",
    "    vflipimg, vflipbox = vflip_with_default_label(image=image, bboxes=bbox)\n",
    "    trans_imgs.append(vflipimg)\n",
    "    trans_boxes.append(vflipbox)\n",
    "    blurimg, blurbox = blur_with_default_label(image=image, bboxes=bbox)\n",
    "    trans_imgs.append(blurimg)\n",
    "    trans_boxes.append(blurbox)\n",
    "\n",
    "    distortimg, distortbox = opticaldistort_with_default_label(image=image, bboxes=bbox)\n",
    "    trans_imgs.append(distortimg)\n",
    "    trans_boxes.append(distortbox)\n",
    "    startx = float(startx) / w\n",
    "    starty = float(starty) / h\n",
    "    endx = float(endx) / w\n",
    "    endy = float(endy) / h\n",
    "    print('X1: {}, y1: {}, x2: {}, y2: {}'.format(startx, starty, endx, endy),end = '\\r')\n",
    "    image = load_img(imgpath, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    targets.append((startx, starty, endx, endy))\n",
    "    filenames.append(filename)\n",
    "print(len(trans_imgs), len(trans_boxes))\n",
    "print(len(data), len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = []\n",
    "traintargets = []\n",
    "names = []\n",
    "errors = 0\n",
    "\n",
    "for i, f in enumerate(trynames):\n",
    "    name = f[0]\n",
    "    names.append(name)\n",
    "    startx = int(f[1])\n",
    "    starty = int(f[2])\n",
    "    endx = int(f[3])\n",
    "    endy = int(f[4])\n",
    "    try:\n",
    "        imgpath = os.path.join('/kaggle/working/Images', name)\n",
    "        image = cv2.imread(imgpath)\n",
    "        (h, w) = image.shape[:2]\n",
    "        bbox = [startx, starty, endx, endy]\n",
    "        bbox = [[int(coord) for coord in bbox]]\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    except (AttributeError, FileNotFoundError):\n",
    "        try:\n",
    "            print('trying with - BOUNDED added')\n",
    "            imgpath = os.path.join(img_path, name).replace('.jpg', ' - BOUNDED.jpg')\n",
    "            image = cv2.imread(imgpath)\n",
    "            (h, w) = image.shape[:2]\n",
    "            bbox = [startx, starty, endx, endy]\n",
    "            bbox = [[int(coord) for coord in bbox]]\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        except (AttributeError, FileNotFoundError):\n",
    "            print('trying .JPG')\n",
    "            imgpath = os.path.join(img_path, name).replace('.jpg', '.JPG')\n",
    "            image = cv2.imread(imgpath)\n",
    "            if image is None:\n",
    "                try:\n",
    "                    imgpath = os.path.join('/kaggle/input/1016-augmented/toAugment', name.replace('jpg', 'JPG'))\n",
    "                    image = cv2.imread(imgpath)\n",
    "                    (h, w) = image.shape[:2]\n",
    "                    bbox = [startx, starty, endx, endy]\n",
    "                    bbox = [[int(coord) for coord in bbox]]\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                except (AttributeError, FileNotFoundError):\n",
    "                    print(f\"Skipping {name} due to an error.\")\n",
    "                    errors += 1\n",
    "                    continue\n",
    "            (h, w) = image.shape[:2]\n",
    "            bbox = [startx, starty, endx, endy]\n",
    "            bbox = [[int(coord) for coord in bbox]]\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    startx = float(startx) / w\n",
    "    starty = float(starty) / h\n",
    "    endx = float(endx) / w\n",
    "    endy = float(endy) / h\n",
    "\n",
    "    print('X1: {}, y1: {}, x2: {}, y2: {}'.format(startx, starty, endx, endy))\n",
    "\n",
    "    image = load_img(imgpath, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    traindata.append(image)\n",
    "    traintargets.append((startx, starty, endx, endy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_calc(bb1, bb2):\n",
    "    true_xmin, true_ymin, true_width, true_height = tf.split(bb1, 4, axis=-1)\n",
    "    bb_xmin, bb_ymin, bb_width, bb_height = tf.split(bb2, 4, axis=-1)\n",
    "\n",
    "    true_xmax = true_xmin + true_width\n",
    "    true_ymax = true_ymin + true_height\n",
    "    bb_xmax = bb_xmin + bb_width\n",
    "    bb_ymax = bb_ymin + bb_height\n",
    "\n",
    "    # calculating area\n",
    "    true_area = true_width * true_height\n",
    "    bb_area = bb_width * bb_height\n",
    "\n",
    "    # calculating intersection coordinates\n",
    "    inter_xmin = tf.maximum(true_xmin, bb_xmin)\n",
    "    inter_ymin = tf.maximum(true_ymin, bb_ymin)\n",
    "    inter_xmax = tf.minimum(true_xmax, bb_xmax)\n",
    "    inter_ymax = tf.minimum(true_ymax, bb_ymax)\n",
    "\n",
    "    inter_width = tf.maximum(0.0, inter_xmax - inter_xmin)\n",
    "    inter_height = tf.maximum(0.0, inter_ymax - inter_ymin)\n",
    "    inter_area = inter_width * inter_height\n",
    "\n",
    "    iou = inter_area / (true_area + bb_area - inter_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def iou_loss(y_true, y_pred):\n",
    "    loss = 1 - iou_calc(y_true, y_pred)\n",
    "    iou_check = tf.reduce_all(loss <= 1)\n",
    "    tf.debugging.assert_scalar(iou_check, message=\"IOU values must be less than or equal to 1.\")\n",
    "    iou_check = tf.reduce_all(loss >= 0)\n",
    "    tf.debugging.assert_scalar(iou_check, message=\"IOU values must be greater than or equal to 0.\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def calculate_ciou_loss(y_true, y_pred):\n",
    "    # Extract the coordinates of the bounding boxes\n",
    "    true_x, true_y, true_w, true_h = tf.unstack(y_true, 4, axis=-1)\n",
    "    pred_x, pred_y, pred_w, pred_h = tf.unstack(y_pred, 4, axis=-1)\n",
    "\n",
    "    # Calculate the intersection coordinates\n",
    "    intersect_x1 = tf.maximum(true_x - true_w / 2.0, pred_x - pred_w / 2.0)\n",
    "    intersect_y1 = tf.maximum(true_y - true_h / 2.0, pred_y - pred_h / 2.0)\n",
    "    intersect_x2 = tf.minimum(true_x + true_w / 2.0, pred_x + pred_w / 2.0)\n",
    "    intersect_y2 = tf.minimum(true_y + true_h / 2.0, pred_y + pred_h / 2.0)\n",
    "\n",
    "    # Calculate the intersection area\n",
    "    intersect_w = tf.maximum(0.0, intersect_x2 - intersect_x1)\n",
    "    intersect_h = tf.maximum(0.0, intersect_y2 - intersect_y1)\n",
    "    intersect_area = intersect_w * intersect_h\n",
    "    print('INTERSECT AREA: {}'.format(intersect_area))\n",
    "\n",
    "    # Calculate the union area\n",
    "    true_area = true_w * true_h\n",
    "    pred_area = pred_w * pred_h\n",
    "    union_area = true_area + pred_area - intersect_area\n",
    "    \n",
    "    print('UNION AREA: {}'.format(union_area))\n",
    "\n",
    "    # Calculate the IoU\n",
    "    iou = intersect_area / tf.maximum(union_area, K.epsilon())\n",
    "    print('IOU: {}'.format(iou))\n",
    "\n",
    "    # Calculate the enclosing box coordinates\n",
    "    enclose_x1 = tf.minimum(true_x - true_w / 2.0, pred_x - pred_w / 2.0)\n",
    "    enclose_y1 = tf.minimum(true_y - true_h / 2.0, pred_y - pred_h / 2.0)\n",
    "    enclose_x2 = tf.maximum(true_x + true_w / 2.0, pred_x + pred_w / 2.0)\n",
    "    enclose_y2 = tf.maximum(true_y + true_h / 2.0, pred_y + pred_h / 2.0)\n",
    "\n",
    "    # Calculate the diagonal distance squared\n",
    "    enclose_w = tf.maximum(0.0, enclose_x2 - enclose_x1)\n",
    "    enclose_h = tf.maximum(0.0, enclose_y2 - enclose_y1)\n",
    "    diagonal_dist_sq = enclose_w**2 + enclose_h**2\n",
    "\n",
    "    # Calculate the center distance squared\n",
    "    center_dist_sq = (true_x - pred_x)**2 + (true_y - pred_y)**2\n",
    "\n",
    "    # Calculate the CIoU loss\n",
    "    ciou = iou - (center_dist_sq / diagonal_dist_sq)\n",
    "\n",
    "    # Return the CIoU loss\n",
    "    #return 1.0 - ciou\n",
    "    return 1.0 - iou\n",
    "\n",
    "def ciou_loss(y_true, y_pred):\n",
    "    loss = calculate_ciou_loss(y_true, y_pred)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype='float32') / 255.0\n",
    "traindata = np.array(traindata, dtype='float32') / 255.0\n",
    "targets = np.array(targets, dtype = 'float32')\n",
    "traintargets = np.array(traintargets, dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = data\n",
    "testImages = traindata\n",
    "trainTargets = targets\n",
    "testTargets = traintargets\n",
    "trainFilenames = filenames\n",
    "testFilenames = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "\n",
    "decay_steps = 300\n",
    "initial_learning_rate = 0.001\n",
    "\n",
    "\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate, decay_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(weights = 'imagenet', include_top = False, input_tensor=Input(shape=(224,224,3)))\n",
    "\n",
    "vgg.trainable = False\n",
    "\n",
    "flatten = vgg.output\n",
    "flatten = Flatten()(flatten)\n",
    "\n",
    "bboxhead = Dense(256, activation = 'relu')(flatten)\n",
    "bboxhead = Dense(128, activation = 'relu')(bboxhead)\n",
    "bboxhead = Dense(64, activation = 'relu')(bboxhead)\n",
    "bboxhead = Dense(32, activation = 'relu')(bboxhead)\n",
    "bboxhead = Dense(4, activation = 'sigmoid')(bboxhead)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = bboxhead)\n",
    "\n",
    "opt = Adam(lr = lr_schedule)\n",
    "model.compile(loss =ciou_loss, optimizer = opt, metrics = [tfa.losses.GIoULoss(), 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def lr_schedule_callback(epoch, lr):\n",
    "    # Log the learning rate at each epoch\n",
    "    print(f\"Learning rate at epoch {epoch+1}: {lr}\")\n",
    "    lr_history.append(lr)\n",
    "    return lr_schedule(epoch)  # U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath='/kaggle/working/best_model.h5',\n",
    "                                      monitor='val_loss',\n",
    "                                      save_best_only=True,\n",
    "                                      mode='min',\n",
    "                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=25,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    "    start_from_epoch=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlength = 300\n",
    "H = model.fit(trainImages, trainTargets, validation_data = (testImages,testTargets), batch_size = 32, epochs = trainlength, verbose = 1, callbacks = [checkpoint_callback, LearningRateScheduler(lr_schedule_callback)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.offline as offline\n",
    "\n",
    "N = 300\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(0, N), y=H.history['loss'], name='train_loss'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(0, N), y=H.history['val_loss'], name='val_loss'))\n",
    "fig.update_layout(title=\"Bounding Box Regression MSE Loss on Training Set\",\n",
    "                  xaxis_title=\"Epochs\",\n",
    "                  yaxis_title=\"Loss\")\n",
    "offline.plot(fig, filename='CIOU graph.html', auto_open=False)\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(0, N), y=H.history['giou_loss'], name='train GIoU'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(0, N), y=H.history['val_giou_loss'], name='val GIoU'))\n",
    "fig.update_layout(title=\"Bounding Box Regression GIoU Loss on Training Set\",\n",
    "                  xaxis_title=\"Epochs\",\n",
    "                  yaxis_title=\"Loss\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"/kaggle/working/model 1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"/kaggle/working/model 1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ID-Cropping Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "source_folder1 = '/kaggle/input/augmented/Images'\n",
    "source_folder2 = '/kaggle/input/augmented-images-2/Images 2'\n",
    "source_folder3 = '/kaggle/input/1016-augmented/Images 3'\n",
    "destination_folder = '/kaggle/working/Images'\n",
    "\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "for i, file_name in enumerate(os.listdir(source_folder1)):\n",
    "    print('Progress: {}/{}'.format(i, len(os.listdir(source_folder1))), end = '\\r')\n",
    "    shutil.copy2(os.path.join(source_folder1, file_name), destination_folder)\n",
    "\n",
    "for o, file_name in enumerate(os.listdir(source_folder2)):\n",
    "    print('Progress: {}/{}'.format(o, len(os.listdir(source_folder2))), end = '\\r')\n",
    "    shutil.copy2(os.path.join(source_folder2, file_name), destination_folder)\n",
    "\n",
    "\n",
    "for u, file_name in enumerate(os.listdir(source_folder3)):\n",
    "    print('Progress: {}/{}'.format(u, len(os.listdir(source_folder3))), end = '\\r')\n",
    "    shutil.copy2(os.path.join(source_folder3, file_name), destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"/kaggle/input/1016-augmented/augmented_boundary_master.xlsx\"\n",
    "img_path = \"/kaggle/working/Images\"\n",
    "df = load_workbook(df_path)\n",
    "df = df.active\n",
    "rows = [[]]\n",
    "data = []\n",
    "targets = []\n",
    "filenames = []\n",
    "trynames = []\n",
    "labels = []\n",
    "idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(2,df.max_row):\n",
    "    tryname = df['A'+str(f)].value\n",
    "    augmented = 0\n",
    "    for effect in ['VFLIP', 'HFLIP', 'DISTORTED', 'MIXED', 'ROTATED', 'SCALED', 'BLURRED']:\n",
    "        if effect in tryname:\n",
    "            augmented = 1\n",
    "            rows.append([df['A'+str(f)].value,df['B'+str(f)].value, df['C'+str(f)].value,df['D'+str(f)].value, df['E'+str(f)].value] )\n",
    "    if augmented != 1:\n",
    "        trynames.append([df['A'+str(f)].value,df['B'+str(f)].value, df['C'+str(f)].value,df['D'+str(f)].value, df['E'+str(f)].value] )\n",
    "rows = rows[1:]\n",
    "print(len(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(rows)\n",
    "random.shuffle(trynames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgnames = []\n",
    "bboxcoords = []\n",
    "trans_imgs = []\n",
    "trans_imgs = []\n",
    "trans_boxes = []\n",
    "for i, f in enumerate(rows):\n",
    "    print('progress: {}/{} *** '.format(i, len(rows)), end = '\\r')\n",
    "    # print(f[0])\n",
    "    filename = f[0]\n",
    "    if filename not in os.listdir('/kaggle/working/Images'):\n",
    "        print('not in here')\n",
    "        continue\n",
    "    if '0164' in filename:\n",
    "        filename = filename.replace('ba6ham', 'cu2val').replace('002','001')\n",
    "        pass\n",
    "    startx = int(f[1])\n",
    "    starty = int(f[2])\n",
    "    endx = int(f[3])\n",
    "    endy = int(f[4])\n",
    "    imgnames.append(filename)\n",
    "    try:\n",
    "        imgpath = os.path.join(img_path, filename)\n",
    "\n",
    "        image = cv2.imread(imgpath)\n",
    "        (h, w) = image.shape[:2]\n",
    "        bbox = [startx, starty, endx, endy]\n",
    "\n",
    "        bbox = [[int(coord) for coord in bbox]]\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            print('trying with - BOUNDED added')\n",
    "            try:\n",
    "                imgpath = os.path.join(img_path, filename).replace('.jpg', ' - BOUNDED.jpg')\n",
    "\n",
    "                image = cv2.imread(imgpath)\n",
    "                (h, w) = image.shape[:2]\n",
    "                bbox = [startx, starty, endx, endy]\n",
    "\n",
    "                bbox = [[int(coord) for coord in bbox]]\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            except AttributeError:\n",
    "                try:\n",
    "                    print('trying .JPG')\n",
    "                    imgpath = os.path.join(img_path, filename).replace('.jpg', '.JPG')\n",
    "\n",
    "                    image = cv2.imread(imgpath)\n",
    "                    (h, w) = image.shape[:2]\n",
    "                    bbox = [startx, starty, endx, endy]\n",
    "\n",
    "                    bbox = [[int(coord) for coord in bbox]]\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                except FileNotFoundError or AttributeError:\n",
    "                    continue\n",
    "        except FileNotFoundError or AttributeError:\n",
    "            continue\n",
    "    hflipimg, hflipbox = hflip_with_default_label(image=image, bboxes=bbox)\n",
    "    trans_imgs.append(hflipimg)\n",
    "    trans_boxes.append(hflipbox)\n",
    "    vflipimg, vflipbox = vflip_with_default_label(image=image, bboxes=bbox)\n",
    "    trans_imgs.append(vflipimg)\n",
    "    trans_boxes.append(vflipbox)\n",
    "    blurimg, blurbox = blur_with_default_label(image=image, bboxes=bbox)\n",
    "    trans_imgs.append(blurimg)\n",
    "    trans_boxes.append(blurbox)\n",
    "\n",
    "    distortimg, distortbox = opticaldistort_with_default_label(image=image, bboxes=bbox)\n",
    "    trans_imgs.append(distortimg)\n",
    "    trans_boxes.append(distortbox)\n",
    "    startx = float(startx) / w\n",
    "    starty = float(starty) / h\n",
    "    endx = float(endx) / w\n",
    "    endy = float(endy) / h\n",
    "    print('X1: {}, y1: {}, x2: {}, y2: {}'.format(startx, starty, endx, endy),end = '\\r')\n",
    "    image = load_img(imgpath, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    targets.append((startx, starty, endx, endy))\n",
    "    filenames.append(filename)\n",
    "print(len(trans_imgs), len(trans_boxes))\n",
    "print(len(data), len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = []\n",
    "traintargets = []\n",
    "names = []\n",
    "errors = 0\n",
    "\n",
    "for i, f in enumerate(trynames):\n",
    "    name = f[0]\n",
    "    names.append(name)\n",
    "    startx = int(f[1])\n",
    "    starty = int(f[2])\n",
    "    endx = int(f[3])\n",
    "    endy = int(f[4])\n",
    "    try:\n",
    "        imgpath = os.path.join('/kaggle/working/Images', name)\n",
    "        image = cv2.imread(imgpath)\n",
    "        (h, w) = image.shape[:2]\n",
    "        bbox = [startx, starty, endx, endy]\n",
    "        bbox = [[int(coord) for coord in bbox]]\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    except (AttributeError, FileNotFoundError):\n",
    "        try:\n",
    "            print('trying with - BOUNDED added')\n",
    "            imgpath = os.path.join(img_path, name).replace('.jpg', ' - BOUNDED.jpg')\n",
    "            image = cv2.imread(imgpath)\n",
    "            (h, w) = image.shape[:2]\n",
    "            bbox = [startx, starty, endx, endy]\n",
    "            bbox = [[int(coord) for coord in bbox]]\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        except (AttributeError, FileNotFoundError):\n",
    "            print('trying .JPG')\n",
    "            imgpath = os.path.join(img_path, name).replace('.jpg', '.JPG')\n",
    "            image = cv2.imread(imgpath)\n",
    "            if image is None:\n",
    "                try:\n",
    "                    imgpath = os.path.join('/kaggle/input/1016-augmented/toAugment', name.replace('jpg', 'JPG'))\n",
    "                    image = cv2.imread(imgpath)\n",
    "                    (h, w) = image.shape[:2]\n",
    "                    bbox = [startx, starty, endx, endy]\n",
    "                    bbox = [[int(coord) for coord in bbox]]\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                except (AttributeError, FileNotFoundError):\n",
    "                    print(f\"Skipping {name} due to an error.\")\n",
    "                    errors += 1\n",
    "                    continue\n",
    "            (h, w) = image.shape[:2]\n",
    "            bbox = [startx, starty, endx, endy]\n",
    "            bbox = [[int(coord) for coord in bbox]]\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    startx = float(startx) / w\n",
    "    starty = float(starty) / h\n",
    "    endx = float(endx) / w\n",
    "    endy = float(endy) / h\n",
    "\n",
    "    print('X1: {}, y1: {}, x2: {}, y2: {}'.format(startx, starty, endx, endy))\n",
    "\n",
    "    image = load_img(imgpath, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    traindata.append(image)\n",
    "    traintargets.append((startx, starty, endx, endy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype='float32') / 255.0\n",
    "traindata = np.array(traindata, dtype='float32') / 255.0\n",
    "targets = np.array(targets, dtype = 'float32')\n",
    "traintargets = np.array(traintargets, dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = data\n",
    "testImages = traindata\n",
    "trainTargets = targets\n",
    "testTargets = traintargets\n",
    "trainFilenames = filenames\n",
    "testFilenames = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "\n",
    "decay_steps = 300\n",
    "initial_learning_rate = 0.0001\n",
    "\n",
    "\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate, decay_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights = 'imagenet', include_top = False, input_tensor=Input(shape=(224,224,3)))\n",
    "\n",
    "freeze_until_layer = 7\n",
    "\n",
    "for layer in base_model.layers[:freeze_until_layer]:\n",
    "    layer.trainable = False\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = base_model.output\n",
    "flatten = Flatten()(flatten)\n",
    "\n",
    "\n",
    "bboxhead = Dense(256, activation = 'relu')(flatten)\n",
    "bboxhead = Dense(128, activation = 'relu')(bboxhead)\n",
    "bboxhead = Dense(64, activation = 'relu')(bboxhead)\n",
    "bboxhead = Dense(32, activation = 'relu')(bboxhead)\n",
    "bboxhead = Dense(4, activation = 'sigmoid')(bboxhead)\n",
    "\n",
    "model = Model(inputs = base_model.input, outputs = bboxhead)\n",
    "\n",
    "opt = Adam(lr = lr_schedule)\n",
    "model.compile(loss =ciou_loss, optimizer = opt, metrics = [tfa.losses.GIoULoss(), 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def lr_schedule_callback(epoch, lr):\n",
    "    # Log the learning rate at each epoch\n",
    "    print(f\"Learning rate at epoch {epoch+1}: {lr}\")\n",
    "    lr_history.append(lr)\n",
    "    return lr_schedule(epoch)  # U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath='/kaggle/working/best_model.h5',\n",
    "                                      monitor='val_loss',\n",
    "                                      save_best_only=True,\n",
    "                                      mode='min',\n",
    "                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=25,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    "    start_from_epoch=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlength = 300\n",
    "H = model.fit(trainImages, trainTargets, validation_data = (testImages,testTargets), batch_size = 32, epochs = trainlength, verbose = 1, callbacks = [checkpoint_callback, LearningRateScheduler(lr_schedule_callback)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.offline as offline\n",
    "\n",
    "N = 300\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(0, N), y=H.history['loss'], name='train_loss'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(0, N), y=H.history['val_loss'], name='val_loss'))\n",
    "fig.update_layout(title=\"Bounding Box Regression CIOU Loss on Training Set\",\n",
    "                  xaxis_title=\"Epochs\",\n",
    "                  yaxis_title=\"Loss\")\n",
    "offline.plot(fig, filename='CIOU graph.html', auto_open=False)\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(0, N), y=H.history['giou_loss'], name='train GIoU'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(0, N), y=H.history['val_giou_loss'], name='val GIoU'))\n",
    "fig.update_layout(title=\"Bounding Box Regression GIoU Loss on Training Set\",\n",
    "                  xaxis_title=\"Epochs\",\n",
    "                  yaxis_title=\"Loss\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(0, N), y=H.history['lr'], name='Learning Rate'))\n",
    "fig.update_layout(title=\"Exponential Decay Learning Rate\",\n",
    "                  xaxis_title=\"Epochs\",\n",
    "                  yaxis_title=\"lr\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"/kaggle/working/model 1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"/kaggle/working/model 1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imutils\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from openpyxl import load_workbook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import mimetypes\n",
    "import argparse\n",
    "import imutils\n",
    "import random\n",
    "from random import sample\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import mimetypes\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "from random import sample\n",
    "\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder1 = '/kaggle/input/example-photoset/example'\n",
    "\n",
    "destination_folder = '/kaggle/working/Images'\n",
    "\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "for i, file_name in enumerate(os.listdir(source_folder1)):\n",
    "    print('Progress: {}/{}'.format(i, len(os.listdir(source_folder1))), end = '\\r')\n",
    "    shutil.copy2(os.path.join(source_folder1, file_name), destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagmodel_json_file = open('/kaggle/input/tag-model/model 1.json', 'r')\n",
    "tagmodel_loaded_model_json = tagmodel_json_file.read()\n",
    "tagmodel_json_file.close()\n",
    "tagmodel = model_from_json(tagmodel_loaded_model_json)\n",
    "# load weights into new model\n",
    "tagmodel.load_weights(\"/kaggle/input/tag-model/best_model.h5\")\n",
    "\n",
    "textmodel_json_file = open('/kaggle/input/getid-model/model 1.json', 'r')\n",
    "textmodel_loaded_model_json = textmodel_json_file.read()\n",
    "textmodel_json_file.close()\n",
    "textmodel = model_from_json(textmodel_loaded_model_json)\n",
    "# load weights into new model\n",
    "textmodel.load_weights(\"/kaggle/input/getid-model/best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagepath = '/kaggle/input/example-photoset/example'\n",
    "\n",
    "print(len(os.listdir(imagepath)))\n",
    "\n",
    "from random import sample\n",
    "\n",
    "\n",
    "for num in range(len(os.listdir(imagepath))):\n",
    "    if num == 0 or num % 2 == 0:\n",
    "        picture = sorted(os.listdir(imagepath))[num]\n",
    "        pic = os.path.join(imagepath, picture)\n",
    "        print(pic)\n",
    "        image = load_img(pic, target_size = (224,224))\n",
    "        image = img_to_array(image) / 255.0\n",
    "        image = np.expand_dims(image, axis = 0)\n",
    "        predtag = tagmodel.predict(image)[0]\n",
    "        (startx, starty, endx, endy) = predtag\n",
    "\n",
    "        image = cv2.imread(pic)\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        (h, w) = image.shape[:2]\n",
    "        startx = int(startx * w)\n",
    "        starty = int(starty * h)\n",
    "        endx = int(endx * w)\n",
    "        endy = int(endy * h)\n",
    "        image = image[int(starty):int(endy), int(startx):int(endx)]\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite('/kaggle/working/cropped/'+ picture, image)\n",
    "    else:\n",
    "        print('tree file', sorted(os.listdir(imagepath))[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/textcropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagepath = '/kaggle/working/cropped'\n",
    "\n",
    "jpg_files = [img for img in os.listdir(imagepath)]\n",
    "\n",
    "print(jpg_files)\n",
    "\n",
    "for img in jpg_files:\n",
    "    myimg = os.path.join(imagepath, img)\n",
    "    image = load_img(myimg, target_size = (224,224))\n",
    "    image = img_to_array(image) / 255.0\n",
    "    image = np.expand_dims(image, axis = 0)\n",
    "    preds = textmodel.predict(image)[0]\n",
    "    (startx, starty, endx, endy) = preds\n",
    "    print(preds)\n",
    "\n",
    "    image = cv2.imread(myimg)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = imutils.resize(image, width=image.shape[1])\n",
    "    (h, w) = image.shape[:2]\n",
    "    startx = int(startx * w)\n",
    "    starty = int(starty * h)\n",
    "    endx = int(endx * w)\n",
    "    endy = int(endy * h)\n",
    "    startx -= int(0.025*startx)\n",
    "    starty -=int(0.025*starty)\n",
    "    endx += int(0.025*endx)\n",
    "    endy += int(0.025*endy)\n",
    "    cv2.rectangle(image, (startx, starty), (endx, endy), (0, 0, 0), 5)\n",
    "    image = image[int(starty):int(endy), int(startx):int(endx)]\n",
    "    cv2.imwrite('/kaggle/working/textcropped/' + img, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def remove_non_numeric(string):\n",
    "    return ''.join(c for c in string if is_number(c))\n",
    "def attempt_read(image, threshold, highestconf, threshoption):\n",
    "    yourtag = 'NO READ'\n",
    "    picture = cv2.imread(image)\n",
    "    graycrop = cv2.cvtColor(picture, cv2.COLOR_BGR2RGB)\n",
    "    graycrop = cv2.cvtColor(graycrop, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    kernel = np.ones((5,5), np.float32)/25\n",
    "    graycrop = cv2.filter2D(graycrop, -1, kernel)\n",
    "    ret, graycrop = cv2.threshold(graycrop, threshold, 255, cv2.THRESH_BINARY)\n",
    "    th2 = cv2.adaptiveThreshold(graycrop,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "                cv2.THRESH_BINARY,11,2)\n",
    "    th3 = cv2.adaptiveThreshold(graycrop,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                cv2.THRESH_BINARY,11,2)\n",
    "    retotsu,thotsu = cv2.threshold(graycrop,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    mydict = {'graycrop': graycrop,'th2': th2, 'th3': th3, 'thotsu': thotsu}\n",
    "    #if threshoption == 'graycrop':\n",
    "        #plt.figure(figsize = (5,5))\n",
    "        #plt.imshow(mydict[threshoption], cmap = 'gray')\n",
    "        #plt.show()\n",
    "    for rotation in range(12):\n",
    "        if highestconf >= 85:\n",
    "            break\n",
    "        angle = rotation * 30\n",
    "        #if rotation != 0:\n",
    "            #print('rotating...', angle,' ', 'degrees', end = '\\r')\n",
    "        rotated_image = imutils.rotate(mydict[threshoption], angle = angle)\n",
    "        for psm in range(6,13+1):\n",
    "            config = '--oem 1 --psm %d -c tessedit_char_whitelist=123456789-' % psm\n",
    "            #print('psm = {}'.format(psm))\n",
    "            d = pytesseract.image_to_data(rotated_image, config = config, output_type = Output.DICT)\n",
    "            #if d['text'] != ['']:\n",
    "                #print('Text Detected: ',d['text'])\n",
    "                #print('Confidence: ', d['conf'])\n",
    "            for idx, i in enumerate(d['text']):\n",
    "                if i != '' and i != '-' and '--' not in i and len(i) > 1:\n",
    "                    i = remove_non_numeric(i)\n",
    "                    #print('predicted label: {}, confidence: {}'.format(i, d['conf'][idx]))\n",
    "                if d['conf'][idx] > (60) or is_number(str(i)):\n",
    "                    if d['conf'][idx] > highestconf and len(i) == 3 or len(i) == 5:\n",
    "                        highestconf = d['conf'][idx]\n",
    "                        if len(i) == 3:\n",
    "                            i = '-'.join(c for c in i)\n",
    "                        yourtag = i\n",
    "                \n",
    "    return('{}***{}'.format(image,yourtag), highestconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = os.listdir('/kaggle/working/textcropped')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))\n",
    "\n",
    "random_indices = random.sample(range(0, len(trainImages)), 20)\n",
    "\n",
    "# Iterate through the random sample of images\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Retrieve the image and preprocess it\n",
    "    path =trainImages[random_indices[i]]\n",
    "    path = os.path.join('/kaggle/working/textcropped/', path)\n",
    "    image = cv2.imread(path)\n",
    "    # Display the image in the current subplot\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the figure with all subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pytesseract\n",
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "from pytesseract import Output\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "image_list = os.listdir('/kaggle/working/textcropped')\n",
    "thresholds = [130,140,150,160,170,180,190, 200,210]\n",
    "threshoptions = ['graycrop','th2', 'th3', 'thotsu']\n",
    "counter = 0\n",
    "scored_tags = []\n",
    "for picture in image_list:\n",
    "    print('Progress: {}/{}'.format(counter+1, len(image_list)))\n",
    "    templabel = 'INITIAL'\n",
    "    highestconf = -100\n",
    "    picture = os.path.join('/kaggle/working/textcropped', picture)\n",
    "    img = cv2.imread(picture)\n",
    "    for thresholdvalue in thresholds:\n",
    "        if highestconf >= 80:\n",
    "                print('final tag: ', templabel)\n",
    "                break\n",
    "        for thresh in threshoptions:\n",
    "            if highestconf >= 80:\n",
    "                break\n",
    "            label, confidence = attempt_read(image = picture,\n",
    "                                             threshold = thresholdvalue,\n",
    "                                             highestconf = 0,\n",
    "                                            threshoption = thresh)\n",
    "\n",
    "            if confidence > highestconf and confidence != -1 and 'NO READ' not in label:\n",
    "                print('replacing highest score ({}) with {}'.format(templabel.replace('.jpg', ''), label+'.jpg'))\n",
    "                templabel = label\n",
    "                highestconf = confidence\n",
    "    if highestconf >= 83:\n",
    "        scored_tags.append('{}***{}.jpg'.format(picture.split('/')[-1], templabel.split('***')[-1].replace('.jpg', '').split('/')[-1]))\n",
    "    elif 'NO READ' not in templabel and 'INITIAL' not in templabel and highestconf < 85:\n",
    "        scored_tags.append('{}***{}-CHECK.jpg'.format(picture.split('/')[-1], templabel.split('***')[-1].replace('.jpg', '').split('/')[-1]))\n",
    "    else:\n",
    "        scored_tags.append('{}***{}.jpg'.format(picture.split('/')[-1], templabel.split('***')[-1].replace('.jpg', '').split('/')[-1]))\n",
    "    print('taglist: ', scored_tags)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder1 = '/kaggle/input/example-photoset/example'\n",
    "\n",
    "destination_folder = '/kaggle/working/Test'\n",
    "\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "for i, file_name in enumerate(os.listdir(source_folder1)):\n",
    "    print('Progress: {}/{}'.format(i, len(os.listdir(source_folder1))), end = '\\r')\n",
    "    shutil.copy2(os.path.join(source_folder1, file_name), destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodtags = 0\n",
    "semitags  = 0\n",
    "badtags = 0\n",
    "for tag in scored_tags:\n",
    "    if 'INITIAL' not in tag and 'CHECK' not in tag:\n",
    "        print(tag)\n",
    "        goodtags += 1\n",
    "    elif 'CHECK' in tag:\n",
    "        semitags +=1\n",
    "    else:\n",
    "        badtags += 1\n",
    "\n",
    "print('{}% good, {}% check'.format(goodtags/len(scored_tags)*100, semitags/len(scored_tags)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piccounter = 0\n",
    "tagcounter = 0 \n",
    "for picture in sorted(os.listdir('/kaggle/working/Test')):\n",
    "    if piccounter % 2 != 0:\n",
    "        oldname = os.path.join('/kaggle/working/Test', picture)\n",
    "        print(tagcounter)\n",
    "        print(oldname)\n",
    "        newname = os.path.join('/kaggle/working/Test', sorted(scored_tags)[tagcounter])\n",
    "        print(newname)\n",
    "        os.rename(oldname,newname)\n",
    "        tagcounter += 1\n",
    "    piccounter += 1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in sorted(os.listdir('/kaggle/working/Test')):\n",
    "    print(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
